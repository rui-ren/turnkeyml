invoke>=2.0.0
onnx>=1.11.0
onnxmltools==1.10.0
torch>=1.12.1
pyyaml>=5.4
typeguard>=2.3.13
packaging>=20.9
numpy<2.0.0
pandas>=1.5.3
fasteners
GitPython>=3.1.40
psutil
wmi
pytz
tqdm

[:extra == "llm-oga-cuda"]
onnxruntime-gpu>=1.19.1

[:platform_system == "Linux" and extra not in "llm-oga-cuda"]
onnxruntime>=1.10.1

[:platform_system == "Windows" and extra != "llm-oga-cuda"]
onnxruntime-directml>=1.19.0

[cuda]
torch@ https://download.pytorch.org/whl/cu118/torch-2.3.1%2Bcu118-cp310-cp310-win_amd64.whl
torchvision@ https://download.pytorch.org/whl/cu118/torchvision-0.18.1%2Bcu118-cp310-cp310-win_amd64.whl
torchaudio@ https://download.pytorch.org/whl/cu118/torchaudio-2.3.1%2Bcu118-cp310-cp310-win_amd64.whl

[llm]
torch>=2.0.0
transformers
accelerate
py-cpuinfo
sentencepiece
datasets
human-eval-windows==1.0.4
fastapi
uvicorn[standard]

[llm-oga-cuda]
onnxruntime-genai-cuda==0.6.0rc1
torch<2.4,>=2.0.0
transformers>4.45.0
turnkeyml[llm]

[llm-oga-hybrid]
onnx==1.16.1
numpy==1.26.4
turnkeyml[llm]

[llm-oga-igpu]
onnxruntime-genai-directml==0.4.0
torch<2.4,>=2.0.0
transformers<4.45.0
turnkeyml[llm]

[llm-oga-npu]
onnx==1.16.0
onnxruntime==1.18.0
numpy==1.26.4
turnkeyml[llm]
